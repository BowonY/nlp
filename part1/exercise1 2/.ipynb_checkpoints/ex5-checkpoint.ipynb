{
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "15 Which nouns are more common in their plural form, rather than their singular form? (Only consider regular plurals, formed with the -s suffix.) \n",
      "http://nltk-book-solutions.wikidot.com/wiki:chapter5#toc0"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Sorted by decreasing frequency of plural form:\n",
        "years=950,year=658\n",
        "eyes=401,eye=122\n",
        "things=368,thing=333\n",
        "members=325,member=137\n",
        "means=310,mean=199\n",
        "students=213,student=131\n",
        "minutes=196,minute=55\n",
        "months=189,month=130\n",
        "conditions=180,condition=91\n",
        "nations=175,nation=139\n",
        "hours=174,hour=145\n",
        "miles=173,mile=48\n",
        "terms=163,term=79\n",
        "friends=162,friend=133\n",
        "sales=133,sale=44\n",
        "arms=121,arm=94\n",
        "products=108,product=87\n",
        "elements=107,element=52\n",
        "leaders=107,leader=74\n",
        "factors=106,factor=71\n",
        "Sorted by decreasing ratio of frequencies:\n",
        "clothes=89,clothe=1\n",
        "headquarters=65,headquarter=1\n",
        "stairs=47,stair=2\n",
        "species=37,specie=2\n",
        "employes=17,employe=1\n",
        "stockholders=26,stockholder=2\n",
        "survivors=13,survivor=1\n",
        "microorganisms=12,microorganism=1\n",
        "ribs=11,rib=1\n",
        "assessors=20,assessor=2\n",
        "kennings=10,kenning=1\n",
        "guts=9,gut=1\n",
        "syllables=9,syllable=1\n",
        "resources=72,resource=9\n",
        "investors=16,investor=2\n",
        "shipments=16,shipment=2\n",
        "teamsters=8,teamster=1\n",
        "accommodations=8,accommodation=1\n",
        "dunes=8,dune=1\n",
        "liberties=8,libertie=1\n"
       ]
      }
     ],
     "input": [
      "import nltk\n",
      "from nltk.corpus import brown\n",
      "from nltk.probability import FreqDist\n",
      "import re\n",
      " \n",
      "noun_sing=re.compile(r\"^(NN|NN\\$|NN\\+.+|NR|NR\\$|NR\\+MD)$\");\n",
      "noun_plur=re.compile(r\"^(NNS|NNS\\$|NNS\\+.+|NRS)$\");\n",
      "fdist=FreqDist(word.lower() for word in brown.words())\n",
      "result=[]\n",
      "for w,t in brown.tagged_words():\n",
      "   if noun_plur.search(t):\n",
      "      w_without_s = re.sub(r's$',r'',w)\n",
      "      if w != w_without_s and fdist[w_without_s]>0:\n",
      "         if fdist[w] > fdist[w_without_s]:\n",
      "            if result.count((w,w_without_s))==0:\n",
      "               result.append((w,w_without_s))\n",
      " \n",
      "def sort2(a,b):\n",
      "   return cmp(fdist[b[0]],fdist[a[0]])\n",
      "result.sort(sort2)\n",
      "print \"Sorted by decreasing frequency of plural form:\"\n",
      "for ws,w in result[:20]:\n",
      "   print ws + \"=\" + str(fdist[ws]) + \",\" + w + \"=\" + str(fdist[w])\n",
      " \n",
      "def sort3(a,b):\n",
      "   return cmp(fdist[b[0]]/fdist[b[1]],fdist[a[0]]/fdist[a[1]])\n",
      "result.sort(sort3)\n",
      "print \"Sorted by decreasing ratio of frequencies:\"\n",
      "for ws,w in result[:20]:\n",
      "   print ws + \"=\" + str(fdist[ws]) + \",\" + w + \"=\" + str(fdist[w])"
     ],
     "language": "python",
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "15-2 Which word has the greatest number of distinct tags? What are they, and what do they represent?"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "15-2 Which word has the greatest number of distinct tags? What are they, and what do they represent"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Words with highest number of tags:\n",
        "that with tags CS,WPS,DT,QL,WPO,CS-HL,DT-NC,NIL,WPS-NC,WPO-NC,CS-NC,WPS-HL\n",
        "A with tags AT,AT-HL,NN,AT-TL,NP-TL,NN-TL,AT-TL-HL,FW-IN,NP,NP-HL,AT-NC\n",
        "in with tags IN,RP,IN-HL,IN-TL,IN-NC,RP-HL,NN,NIL,RP-NC,FW-IN\n",
        "to with tags TO,IN,IN-HL,TO-HL,IN-TL,NPS,NIL,QL,TO-NC,IN-NC\n",
        ": with tags :,:-HL,NP,:-TL,.,.-HL,,,IN,NIL\n",
        "a with tags AT,AT-HL,FW-IN,NIL,AT-NC,NN,FW-IN-TL,AT-TL\n",
        "fit with tags JJ,VB,VBN,NN,VB-HL,NN-HL,VBD\n",
        "home with tags NR,NN,NN-HL,NR-HL,NR-NC,NN-NC,VB\n",
        "for with tags IN,IN-TL,IN-HL,CS,RB,NN,IN-NC\n",
        "I with tags PPSS,NN,PPSS-NC,NN-TL,NP,NIL,PPSS-HL\n",
        "as with tags CS,QL,CS-HL,IN,CS-TL,RB,NIL\n",
        "it with tags PPS,PPO,PPO-HL,PPS-HL,PPS-NC,PPO-NC,UH\n",
        "out with tags RP,IN,PP$,RP-HL,IN-HL,RB-NC,RP-NC\n",
        "That with tags DT,CS,DT-TL,WPS-TL,DT-HL,WPS,QL\n",
        "well with tags QL,RB,JJ,NN,UH,QL-HL,VB\n",
        "Chinese with tags JJ,JJ-HL,NP,NPS,JJ-TL,JJ-NC,NP-NC\n",
        "Little with tags NP,JJ-TL,AP,JJ-HL,AP-HL,QL,JJ\n",
        "Long with tags JJ-TL,JJ,RB,NP-HL,NP,RB-HL,QL\n",
        "one with tags CD,PN,CD-HL,CD-NC,PN-NC,DTX\n",
        "more with tags AP,QL,RBR,AP-HL,NIL,RBR-NC\n"
       ]
      }
     ],
     "input": [
      "tags={}\n",
      "for w,t in brown.tagged_words():\n",
      "   if not(w in tags):\n",
      "      tags[w]=[]\n",
      "   if tags[w].count(t)==0:\n",
      "      tags[w].append(t)\n",
      "words=tags.keys()\n",
      "def sort4(a,b):\n",
      "   return cmp(len(tags[b]),len(tags[a]))\n",
      "words.sort(sort4)\n",
      " \n",
      "print \"Words with highest number of tags:\"\n",
      "for w in words[:20]:\n",
      "   print w + \" with tags \" + ','.join(tags[w])"
     ],
     "language": "python",
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "List tags in order of decreasing frequency. What do the 20 most frequent tags represent?"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most frequent tags:\n",
        "NN: 152470\n",
        "IN: 120557\n",
        "AT: 97959\n",
        "JJ: 64028\n",
        ".: 60638\n",
        ",: 58156\n",
        "NNS: 55110\n",
        "CC: 37718\n",
        "RB: 36464\n",
        "NP: 34476\n",
        "VB: 33693\n",
        "VBN: 29186\n",
        "VBD: 26167\n",
        "CS: 22143\n",
        "PPS: 18253\n",
        "VBG: 17893\n",
        "PP$: 16872\n",
        "TO: 14918\n",
        "PPSS: 13802\n",
        "CD: 13510\n"
       ]
      }
     ],
     "input": [
      "tagfreq={}\n",
      "for w,t in brown.tagged_words():\n",
      "   if t in tagfreq:\n",
      "      tagfreq[t]+=1\n",
      "   else:\n",
      "      tagfreq[t]=1\n",
      "def sort5(a,b):\n",
      "   return cmp(tagfreq[b],tagfreq[a])\n",
      "tags=tagfreq.keys()\n",
      "tags.sort(sort5)\n",
      "print \"Most frequent tags:\"\n",
      "for t in tags[:20]:\n",
      "   print t + \": \" + str(tagfreq[t])"
     ],
     "language": "python",
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "where NN means noun, IN preposition, AT article, JJ adjective, . sentence terminator, , comma, NNS noun plural common, CC conjunction coordinating, etc.\n",
      "\n",
      "d.\n",
      "Which tags are nouns most commonly found after? What do these tags represent?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Most frequent tags preceding nouns:\n",
      "AT: 59656\n",
      "JJ: 40864\n",
      "IN: 24012\n",
      "NN: 17789\n",
      "PP$: 12241\n",
      "CC: 6610"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "where AT means article, JJ adjectivs, IN preposition, NN noun, etc.\n",
      "\n",
      "Exercise 24"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "#import nltk\n",
      "from nltk.corpus import brown\n",
      "from nltk.probability import FreqDist\n",
      "import re\n",
      " \n",
      "brown_tagged_sents=brown.tagged_sents(categories='news')\n",
      "brown_sents=brown.sents(categories='news')\n",
      " \n",
      "tagger=[0,0,0,0,0,0,0,0]\n",
      " \n",
      "tags=[t for (w,t) in brown.tagged_words(categories='news')]\n",
      "maxtag=nltk.FreqDist(tags).max()\n",
      "tagger[0]=nltk.DefaultTagger(maxtag)\n",
      "default_eval=tagger[0].evaluate(brown_tagged_sents)\n",
      " \n",
      "test_size = int(len(brown_tagged_sents) * 0.1)\n",
      "evaluation=[default_eval,0,0,0,0,0,0,0]\n",
      "print \"WITHOUT BACKOFF:\"\n",
      "print \"0-grams: \" + str(default_eval)\n",
      "for N in xrange(1,7):\n",
      "   for C in xrange(10):\n",
      "      if C==0:\n",
      "         train_sents = brown_tagged_sents[(C+1)*test_size:]\n",
      "      else:\n",
      "         train_sents = brown_tagged_sents[:C*test_size] + brown_tagged_sents[(C+1)*test_size:]\n",
      "      test_sents = brown_tagged_sents[C*test_size:(C+1)*test_size]\n",
      "      tagger[N]=nltk.NgramTagger(N,train=train_sents)\n",
      "      evaluation[N] += tagger[N].evaluate(test_sents)\n",
      "   evaluation[N] /= 10\n",
      "   print str(N) + \"-grams: \" + str(evaluation[N])\n",
      " \n",
      "evaluationbo=[default_eval,0,0,0,0,0,0,0]\n",
      "print \"WITH BACKOFF:\"\n",
      "print \"0-grams: \" + str(default_eval)\n",
      "for N in xrange(1,7):\n",
      "   for C in xrange(10):\n",
      "      if C==0:\n",
      "         train_sents = brown_tagged_sents[(C+1)*test_size:]\n",
      "      else:\n",
      "         train_sents = brown_tagged_sents[:C*test_size] + brown_tagged_sents[(C+1)*test_size:]\n",
      "      test_sents = brown_tagged_sents[C*test_size:(C+1)*test_size]\n",
      "      tagger[N]=nltk.NgramTagger(N,train=train_sents,backoff=tagger[N-1])\n",
      "      evaluationbo[N] += tagger[N].evaluate(test_sents)\n",
      "   evaluationbo[N] /= 10\n",
      "   print str(N) + \"-grams: \" + str(evaluationbo[N])\n",
      " \n",
      "import pylab\n",
      "pylab.plot(xrange(7),evaluation,'-bo')\n",
      "pylab.plot(xrange(7),evaluationbo,'-ro')\n",
      "pylab.title('Performance of n-gram taggers for n=0,...,6')\n",
      "pylab.xlabel('n of n-grams')\n",
      "pylab.ylabel('performance')\n",
      "pylab.show()"
     ],
     "language": "python"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "b.\n",
      "Estimate the training data required for these taggers, assuming a vocabulary size of 105 and a tagset size of 102.\n",
      "\n",
      "I haven't understood this part of the exercise, so I haven't treated it.\n",
      "\n",
      "Exercice 28\n",
      "Experiment with taggers using the simplified tagset (or make one of your own by discarding all but the first character of each tag name). Such a tagger has fewer distinctions to make, but much less information on which to base its work. Discuss your findings.\n",
      "\n",
      "It suffices to change the following two lines of Exercice 24:"
     ]
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "brown_tagged_sents=brown.tagged_sents(categories='news')\n",
      "tags=[t for (w,t) in brown.tagged_words(categories='news')]"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      "#into\n",
      "brown_tagged_sents=brown.tagged_sents(categories='news',simplify_tags=True)\n",
      "tags=[t for (w,t) in brown.tagged_words(categories='news',simplify_tags=True)]"
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named pylab",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-25237e4de4d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m     \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named pylab"
       ]
      }
     ],
     "input": [
      "from pylab import *\n",
      "\n",
      "x = linspace(-1.6, 1.6, 10000)\n",
      "f = lambda x: (sqrt(cos(x)) * cos(200 * x) + sqrt(abs(x)) - 0.7) * \\\n",
      "    pow((4 - x * x), 0.01)\n",
      "plot(x, map(f, x))\n",
      "show()"
     ],
     "language": "python",
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    },
    {
     "cell_type": "code",
     "metadata": {},
     "outputs": [],
     "input": [
      ""
     ],
     "language": "python"
    }
   ]
  }
 ],
 "cells": [],
 "metadata": {
  "name": "",
  "signature": "sha256:8f62f8e45be8ead22652f28dc4168787c5b801f03f6465c4555c3c0c0960fecc"
 },
 "nbformat": 3,
 "nbformat_minor": 0
}