{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장. 링크드인 마이닝 : 직책 다면화, 동료들 클러스터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 바벨피쉬 / 파이썬을 이용한 자연어처리 기초 : 파트3 - '소셜 웹 마이닝'[1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차례 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3.1 개요\n",
    "* 3.2 링크드인 API 탐구\n",
    "* 3.3 데이터 클러스터링에 대한 집중 훈련\n",
    "* 3.4 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 링크드인 - https://www.linkedin.com/\n",
    "* 링크드인의 데이터는 다른 소셜 네트워크와 본질적으로 상당히 다르다 \n",
    "    - '세미정장 드레스코드를 가진 사적인 이벤트로 비유할 수 있을 것이다'\n",
    "* 이 챕터에서는 몇가지 기본적인 데이터 마이닝 기법을 소개한다.\n",
    "    - 인맥 중 직책과 같은 기준에 따랐을 때 가장 유사한 사람이 누구인가?\n",
    "    - 인맥 중 여러분이 일하고 싶은 회사에서 일했던 사람은 누구인가?\n",
    "    - 인맥들이 지리적으로 가장 많이 살고 있는 곳은 어디인가?\n",
    "* 이 장에서 배울 내용\n",
    "    - 링크드인 개발자 플랫폼 & API 요청하기\n",
    "    - 일반적인 클러스터링 유형 세 가지와, 거의 모든 문제 영역에 적용되는 기본적인 머신러닝 주제\n",
    "    - 데이터 정리(data cleansing ) 및 정규화(normalization)\n",
    "    - 좌표 부여(Geocoding), 원문의 장소에 대한 언급으로부터 좌표 집합에 도달하기 위한 수단\n",
    "    - 지리적 데이터를 구글 어스(Google Earth)와 통계 지도에 시각화하기\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 링크드인 API 탐구"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3.2.1 링크드인 API 요청\n",
    "* 3.2.2 링크드인 인맥을 CSV 파일로 내려받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 링크드인 API 요청"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 링크드인 API 사용권한 획득 단계 [3,4,5]\n",
    "* 1) 링크드인 개발자 플랫폼에서 Application 만들기\n",
    "* 2) Client ID와 Client Secet 얻기\n",
    "* 3) 인증요청\n",
    "* 4) authorization_code 획득\n",
    "* 5) access_token 획득\n",
    "* 6) API 사용 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고: 링크드인 API + oauth2 사용법\n",
    "* https://developer.linkedin.com/docs/oauth2\n",
    "* http://www.slideshare.net/KamyarMohager/o-auth-2-and-linked-inpdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) 링크드인 개발자 플랫폼에서 Application 만들기\n",
    "\n",
    "*  https://www.linkedin.com/secure/developer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.1.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.2.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Client ID와 Client Secet 얻기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_CLIENT_ID = '754srtu0p03l9l'\n",
    "D_CLIENT_SECRET = 'tQ2fFx1XOjuE9FjM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.3.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) 인증요청"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 인증요청 단계 \n",
    "* a) Redirect URLs를 등록한다\n",
    "* b) 인증요청 API를 형식에 호출한다\n",
    "    - API : https://www.linkedin.com/uas/oauth2/authorization\n",
    "    - 파라미터\n",
    "        - response_type\n",
    "        - client_id\n",
    "        - redirect_uri\n",
    "        - state\n",
    "        - scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Redirect URLs를 등록한다 \n",
    "* 아무 페이지나 등록해도 된다. 실제 웹에서 접근할수만 있으면 괜찮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_REDIRECT_URL = 'http://babelpish.github.io/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.4.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.5.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) 인증요청 API를 형식에 호출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * GET 방식이므로 쉽게 하려면 웹브라우저 주소창에서 호출하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/uas/oauth2/authorization?response_type=code&client_id=754srtu0p03l9l&redirect_uri=http://babelpish.github.io/&state=987654321&scope=r_basicprofile\n"
     ]
    }
   ],
   "source": [
    "AUTH_API = 'https://www.linkedin.com/uas/oauth2/authorization'\n",
    "STATE_STR = '987654321'\n",
    "SCOPE_STR = 'r_basicprofile'\n",
    "\n",
    "AUTH_URL = AUTH_API + '?' \\\n",
    "                                + 'response_type=' + 'code' + '&' \\\n",
    "                                + 'client_id=' + D_CLIENT_ID + '&' \\\n",
    "                                + 'redirect_uri=' + D_REDIRECT_URL + '&' \\\n",
    "                                + 'state=' + STATE_STR + '&' \\\n",
    "                                + 'scope=' + SCOPE_STR \n",
    "                    \n",
    "print AUTH_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  4) authorization_code 획득"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 위의 URL을 웹브라우저에 넣는다.\n",
    "* 그러면 아래와 같이 자신의 링크드인 계정에서 인증하는 화면이 나온다\n",
    "* 아이디랑 암호 넣어서 인증해주자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.6.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 엑세스 허용하면\n",
    "    - 우리가 설정했던 리다이렉트 페이지로 화면이 넘어가고\n",
    "    - 브라우저 상단 주소가 변해있다.  \n",
    "        - http://babelpish.github.io/?code=AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY&state=987654321\n",
    "    - 그 주소 안에 정보 중에 code라고 되어 있는 부분이 authorization_code 이다. \n",
    "        -  code=AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY\n",
    "        - authorization_code \n",
    "            -  AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY\n"
     ]
    }
   ],
   "source": [
    "D_AUTHORIZATION_CODE =  'AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY'\n",
    "print D_AUTHORIZATION_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 참고) Advanced REST client를 쓰면 편하다.\n",
    "* https://chrome.google.com/webstore/detail/advanced-rest-client/hgmloofddffdnphfgcellkdfbfbjeloo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.7.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) access_token 획득"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 여기까지 왔으면, 다른 API들을 사용하기 위해 필수적인 access_token을 얻을 자격이 되었다.\n",
    "* access_token 획득 API를 호출한다\n",
    "    - API - https://www.linkedin.com/uas/oauth2/accessToken\n",
    "    - 파라미터 \n",
    "        - grant_type\n",
    "        - code\n",
    "        - redirect_uri\n",
    "* 그런데 위의 authorization_code 얻은 후, 20초 이내로 토큰을 얻어야 한다. 즉, 빨리 API를 호출해야 한다.\n",
    "* 문서상에는 POST 방식으로 해야한다고 하지만, GET도 된다. 즉, 얼른 API URL을 완성해서 브러우저 주소창에 넣을 것.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/uas/oauth2/accessToken?grant_type=authorization_code&code=AQRhuylC_US9QtgttkPNNOwpfY9pyfvZAZ6Bs_9EKoA7qLAIQspU6jQwD9a_S--XH4tpsif_WnBN_42T-IaWflYvWgxDTl3mIO81E20zBqGfY2Mx9dY&redirect_uri=http://babelpish.github.io/&client_id=754srtu0p03l9l&client_secret=tQ2fFx1XOjuE9FjM\n"
     ]
    }
   ],
   "source": [
    "ATOKEN_API = 'https://www.linkedin.com/uas/oauth2/accessToken'\n",
    "\n",
    "ATOKEN_URL = ATOKEN_API + '?' \\\n",
    "                                + 'grant_type=' + 'authorization_code' + '&' \\\n",
    "                                + 'code=' + D_AUTHORIZATION_CODE + '&' \\\n",
    "                                + 'redirect_uri=' + D_REDIRECT_URL + '&' \\\n",
    "                                + 'client_id=' + D_CLIENT_ID + '&' \\\n",
    "                                + 'client_secret=' + D_CLIENT_SECRET\n",
    "                    \n",
    "print ATOKEN_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 성공하면 브라우저 화면에 결과가 다음처럼 나온다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"access_token\":\"AQXfELi0qc3wEVDshes3VEaAi2y6aC_e88W6paqVQX4en53OVEOaEzuhhHzJnLNu-EW0bfo9SfcrshPYX0pJuz3uUbBQRvE6q4AJqTjgQchg-vEtslBBgwH5AUBcV1goGu_G4AcM5WAIvkI0vdyCKYxL1bEh1FZ3cLt-PMQLdzMae7XsRkM\",\"expires_in\":5183999}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_ACCESS_TOKEN = 'AQXfELi0qc3wEVDshes3VEaAi2y6aC_e88W6paqVQX4en53OVEOaEzuhhHzJnLNu-EW0bfo9SfcrshPYX0pJuz3uUbBQRvE6q4AJqTjgQchg-vEtslBBgwH5AUBcV1goGu_G4AcM5WAIvkI0vdyCKYxL1bEh1FZ3cLt-PMQLdzMae7XsRkM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) API 사용 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.linkedin.com/v1/people/~?oauth2_access_token=AQXfELi0qc3wEVDshes3VEaAi2y6aC_e88W6paqVQX4en53OVEOaEzuhhHzJnLNu-EW0bfo9SfcrshPYX0pJuz3uUbBQRvE6q4AJqTjgQchg-vEtslBBgwH5AUBcV1goGu_G4AcM5WAIvkI0vdyCKYxL1bEh1FZ3cLt-PMQLdzMae7XsRkM\n"
     ]
    }
   ],
   "source": [
    "PEOPLE_API = 'https://api.linkedin.com/v1/people/~'\n",
    "\n",
    "PEOPLE_URL = PEOPLE_API + '?' \\\n",
    "                                + 'oauth2_access_token=' + D_ACCESS_TOKEN\n",
    "                    \n",
    "print PEOPLE_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 헤더에 넣으려면 다음처럼 해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorization:  Bearer AQXfELi0qc3wEVDshes3VEaAi2y6aC_e88W6paqVQX4en53OVEOaEzuhhHzJnLNu-EW0bfo9SfcrshPYX0pJuz3uUbBQRvE6q4AJqTjgQchg-vEtslBBgwH5AUBcV1goGu_G4AcM5WAIvkI0vdyCKYxL1bEh1FZ3cLt-PMQLdzMae7XsRkM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 요런 호출은 Advanced REST Client를 쓰면 좀 더 편하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/images/LinkedIn-app.8.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 예제 3.1. 개발과 데이터 접근에 적합한 엑세스 토큰을 받기 위해 링크드인 OAuth 인증 증명 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* python-linkedin을 사용해서 좀 더 편하게 엑세스 토큰 발급을 받을 수 있다.\n",
    "* http://ozgur.github.io/python-linkedin/\n",
    "* 책의 예제는 ouath 1.0 방식이므로, 패키지 공식 사이트를 참조한 코드로 수정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# !pip install python-linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from linkedin import linkedin\n",
    "\n",
    "\n",
    "API_KEY = D_CLIENT_ID\n",
    "API_SECRET = D_CLIENT_SECRET\n",
    "RETURN_URL = D_REDIRECT_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r_basicprofile',\n",
       " 'rw_nus',\n",
       " 'r_network',\n",
       " 'r_contactinfo',\n",
       " 'w_messages',\n",
       " 'rw_groups',\n",
       " 'r_emailaddress',\n",
       " 'r_fullprofile']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " linkedin.PERMISSIONS.enums.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perms = ['r_basicprofile',\n",
    "         'r_emailaddress',\n",
    "         'rw_company_admin',\n",
    "         'w_share'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/uas/oauth2/authorization?scope=r_basicprofile%20r_emailaddress%20rw_company_admin%20w_share&state=e94ce89dc1b89a4eb207aa27e3ae534e&redirect_uri=http%3A//babelpish.github.io/&response_type=code&client_id=754srtu0p03l9l\n"
     ]
    }
   ],
   "source": [
    "authentication = linkedin.LinkedInAuthentication(API_KEY, API_SECRET, RETURN_URL, perms) #[linkedin.PERMISSIONS.enums.values()[0]])\n",
    "print authentication.authorization_url  # open this url on your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "application = linkedin.LinkedInApplication(authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AccessToken(access_token=u'AQUvfXDqVybCF2xM4YT6w-lBN5Y61aAdOgAceDJOXIw_G_z0PT4af3zHuvH5tGW9WaFbcWzj39TXCKkpEmRQySgxLzUkRK6LHP7aox3amOwvVlITkORwvUW96B0cD4kr57pQWdstLw_EiHS6CUDzPMnxCZ4L7hv-0-XeWAbWj5K_KmAqK-c', expires_in=5183999)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authentication.authorization_code = 'AQQKzOZKwSRSHPZiC65WlhEzvQpE19AG8baucXmd5RQfr1EzfRsS_KBjJz8-L_2jmvkwPiYzqOpytd573aVM4cDG0Wk15df0Alwayzz6i-S2tOaEXuc'\n",
    "authentication.get_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{u'firstName': u'\\ubb34\\uc131',\n",
       " u'headline': u'\\ucf54\\ub09c\\ud14c\\ud06c\\ub180\\ub85c\\uc9c0 \\uc5f0\\uad6c\\uc6d0',\n",
       " u'id': u'IKxFbKel6-',\n",
       " u'lastName': u'\\uae40',\n",
       " u'siteStandardProfileRequest': {u'url': u'https://www.linkedin.com/profile/view?id=151455949&authType=name&authToken=7gdB&trk=api*a4598841*s4915561*'}}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application.get_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 3-2. 링크드인 인맥을 추출하여 디스크에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    },
    {
     "ename": "LinkedInError",
     "evalue": "403 Client Error: Forbidden: Unknown Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinkedInError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-57613b951ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapplication\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/linkedin/linkedin.pyc\u001b[0m in \u001b[0;36mget_connections\u001b[1;34m(self, member_id, member_url, selectors, params, headers)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mraise_for_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/linkedin/utils.pyc\u001b[0m in \u001b[0;36mraise_for_error\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 message = '%s: %s' % (response.get('error', error.message),\n\u001b[0;32m     62\u001b[0m                                       response.get('error_description', 'Unknown Error'))\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLinkedInError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLinkedInError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinkedInError\u001b[0m: 403 Client Error: Forbidden: Unknown Error"
     ]
    }
   ],
   "source": [
    "application.get_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    },
    {
     "ename": "LinkedInError",
     "evalue": "403 Client Error: Forbidden: Unknown Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinkedInError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-502095745996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mconnections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapplication\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_connections\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mconnections_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'resources/linkedin_connections.json'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/linkedin/linkedin.pyc\u001b[0m in \u001b[0;36mget_connections\u001b[1;34m(self, member_id, member_url, selectors, params, headers)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         \u001b[0mraise_for_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/moosung/.venv/nlp/local/lib/python2.7/site-packages/linkedin/utils.pyc\u001b[0m in \u001b[0;36mraise_for_error\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m     61\u001b[0m                 message = '%s: %s' % (response.get('error', error.message),\n\u001b[0;32m     62\u001b[0m                                       response.get('error_description', 'Unknown Error'))\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mLinkedInError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mLinkedInError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinkedInError\u001b[0m: 403 Client Error: Forbidden: Unknown Error"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "connections = application.get_connections()\n",
    "\n",
    "connections_data = 'resources/linkedin_connections.json'\n",
    "\n",
    "f = open(connections_data, 'w')\n",
    "f.write(json.dumps(connections, indent=1))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Execute this cell if you need to reload data...\n",
    "import json\n",
    "connections = json.loads(open('resources/ch03-linkedin/linkedin_connections.json').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Should you need to revoke account access from your application or any other OAuth application, you can do so at [https://www.linkedin.com/secure/settings?userAgree=&goback=%2Enas_*1_*1_*1](https://www.linkedin.com/secure/settings?userAgree=&goback=%2Enas_*1_*1_*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3. Pretty-printing your LinkedIn connections' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable # pip install prettytable\n",
    "\n",
    "pt = PrettyTable(field_names=['Name', 'Location'])\n",
    "pt.align = 'l'\n",
    "\n",
    "[ pt.add_row((c['firstName'] + ' ' + c['lastName'], c['location']['name'])) \n",
    "  for c in connections['values']\n",
    "      if c.has_key('location')]\n",
    "\n",
    "print pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4. Displaying job position history for your profile and a connection's profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# See http://developer.linkedin.com/documents/profile-fields#fullprofile\n",
    "# for details on additional field selectors that can be passed in for\n",
    "# retrieving additional profile information.\n",
    "\n",
    "# Display your own positions...\n",
    "\n",
    "my_positions = app.get_profile(selectors=['positions'])\n",
    "print json.dumps(my_positions, indent=1)\n",
    "\n",
    "# Display positions for someone in your network...\n",
    "\n",
    "# Get an id for a connection. We'll just pick the first one.\n",
    "connection_id = connections['values'][0]['id']\n",
    "connection_positions = app.get_profile(member_id=connection_id, \n",
    "                                       selectors=['positions'])\n",
    "print json.dumps(connection_positions, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5. Using field selector syntax to request additional details for APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See http://developer.linkedin.com/documents/understanding-field-selectors\n",
    "# for more information on the field selector syntax\n",
    "\n",
    "my_positions = app.get_profile(selectors=['positions:(company:(name,industry,id))'])\n",
    "print json.dumps(my_positions, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 링크드인 인맥을 CSV 파일로 내려받기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 데이터 클러스터링에 대한 집중 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3.3.1 사용자 경험을 증가시키는 클러스터링\n",
    "* 3.3.2 분석을 위한 데이터 정규화\n",
    "    - 3.3.2.1 회사를 정규화하고 개수 세기\n",
    "    - 3.3.2.2 직책을 정규화하고 개수 세기\n",
    "    - 3.3.2.3 위치를 정규화하고 개수 세기 \n",
    "    - 3.3.2.4 통계지도로 좌표 시각화\n",
    "* 3.3.3 유사도 측정\n",
    "* 3.3.4 클러스터링 알고리즘\n",
    "    - 3.3.4.1 그리디(Greedy) 클러스터링\n",
    "    - 3.3.4.2 계층적 클러스터링\n",
    "    - 3.3.4.3 K-평균 클러스터링\n",
    "    - 3.3.4.4. 구글 어스를 이용한 지리적 클러스터링 시각화화화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6. Simple normalization of company suffixes from address book data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
    "# http://www.linkedin.com/people/export-settings at the following\n",
    "# location: resources/ch03-linkedin/my_connections.csv\n",
    "\n",
    "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
    "\n",
    "# Define a set of transforms that converts the first item\n",
    "# to the second item. Here, we're simply handling some\n",
    "# commonly known abbreviations, stripping off common suffixes, \n",
    "# etc.\n",
    "\n",
    "transforms = [(', Inc.', ''), (', Inc', ''), (', LLC', ''), (', LLP', ''),\n",
    "               (' LLC', ''), (' Inc.', ''), (' Inc', '')]\n",
    "\n",
    "csvReader = csv.DictReader(open(CSV_FILE), delimiter=',', quotechar='\"')\n",
    "contacts = [row for row in csvReader]\n",
    "companies = [c['Company'].strip() for c in contacts if c['Company'].strip() != '']\n",
    "\n",
    "for i, _ in enumerate(companies):\n",
    "    for transform in transforms:\n",
    "        companies[i] = companies[i].replace(*transform)\n",
    "\n",
    "pt = PrettyTable(field_names=['Company', 'Freq'])\n",
    "pt.align = 'l'\n",
    "c = Counter(companies)\n",
    "[pt.add_row([company, freq]) \n",
    " for (company, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
    "     if freq > 1]\n",
    "print pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 7. Standardizing common job titles and computing their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
    "# http://www.linkedin.com/people/export-settings at the following\n",
    "# location: resources/ch03-linkedin/my_connections.csv\n",
    "\n",
    "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
    "\n",
    "transforms = [\n",
    "    ('Sr.', 'Senior'),\n",
    "    ('Sr', 'Senior'),\n",
    "    ('Jr.', 'Junior'),\n",
    "    ('Jr', 'Junior'),\n",
    "    ('CEO', 'Chief Executive Officer'),\n",
    "    ('COO', 'Chief Operating Officer'),\n",
    "    ('CTO', 'Chief Technology Officer'),\n",
    "    ('CFO', 'Chief Finance Officer'),\n",
    "    ('VP', 'Vice President'),\n",
    "    ]\n",
    "\n",
    "csvReader = csv.DictReader(open(CSV_FILE), delimiter=',', quotechar='\"')\n",
    "contacts = [row for row in csvReader]\n",
    "\n",
    "# Read in a list of titles and split apart\n",
    "# any combined titles like \"President/CEO.\"\n",
    "# Other variations could be handled as well, such\n",
    "# as \"President & CEO\", \"President and CEO\", etc.\n",
    "\n",
    "titles = []\n",
    "for contact in contacts:\n",
    "    titles.extend([t.strip() for t in contact['Job Title'].split('/')\n",
    "                  if contact['Job Title'].strip() != ''])\n",
    "\n",
    "# Replace common/known abbreviations\n",
    "\n",
    "for i, _ in enumerate(titles):\n",
    "    for transform in transforms:\n",
    "        titles[i] = titles[i].replace(*transform)\n",
    "\n",
    "# Print out a table of titles sorted by frequency\n",
    "\n",
    "pt = PrettyTable(field_names=['Title', 'Freq'])\n",
    "pt.align = 'l'\n",
    "c = Counter(titles)\n",
    "[pt.add_row([title, freq]) \n",
    " for (title, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
    "     if freq > 1]\n",
    "print pt\n",
    "\n",
    "# Print out a table of tokens sorted by frequency\n",
    "\n",
    "tokens = []\n",
    "for title in titles:\n",
    "    tokens.extend([t.strip(',') for t in title.split()])\n",
    "pt = PrettyTable(field_names=['Token', 'Freq'])\n",
    "pt.align = 'l'\n",
    "c = Counter(tokens)\n",
    "[pt.add_row([token, freq]) \n",
    " for (token, freq) in sorted(c.items(), key=itemgetter(1), reverse=True) \n",
    "     if freq > 1 and len(token) > 2]\n",
    "print pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 8. Geocoding locations with Microsoft Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy import geocoders\n",
    "\n",
    "GEO_APP_KEY = '' # XXX: Get this from https://www.bingmapsportal.com\n",
    "g = geocoders.Bing(GEO_APP_KEY)\n",
    "print g.geocode(\"Nashville\", exactly_one=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 9. Geocoding locations of LinkedIn connections with Microsoft Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy import geocoders\n",
    "\n",
    "GEO_APP_KEY = '' # XXX: Get this from https://www.bingmapsportal.com\n",
    "g = geocoders.Bing(GEO_APP_KEY)\n",
    "\n",
    "transforms = [('Greater ', ''), (' Area', '')]\n",
    "\n",
    "results = {}\n",
    "for c in connections['values']:\n",
    "    if not c.has_key('location'): continue\n",
    "        \n",
    "    transformed_location = c['location']['name']\n",
    "    for transform in transforms:\n",
    "        transformed_location = transformed_location.replace(*transform)\n",
    "    geo = g.geocode(transformed_location, exactly_one=False)\n",
    "    if geo == []: continue\n",
    "    results.update({ c['location']['name'] : geo })\n",
    "    \n",
    "print json.dumps(results, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 10. Parsing out states from Bing geocoder results using a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Most results contain a response that can be parsed by\n",
    "# picking out the first two consecutive upper case letters \n",
    "# as a clue for the state\n",
    "pattern = re.compile('.*([A-Z]{2}).*')\n",
    "    \n",
    "def parseStateFromBingResult(r):\n",
    "    result = pattern.search(r[0][0])\n",
    "    if result == None: \n",
    "        print \"Unresolved match:\", r\n",
    "        return \"???\"\n",
    "    elif len(result.groups()) == 1:\n",
    "        print result.groups()\n",
    "        return result.groups()[0]\n",
    "    else:\n",
    "        print \"Unresolved match:\", result.groups()\n",
    "        return \"???\"\n",
    "\n",
    "    \n",
    "transforms = [('Greater ', ''), (' Area', '')]\n",
    "\n",
    "results = {}\n",
    "for c in connections['values']:\n",
    "    if not c.has_key('location'): continue\n",
    "    if not c['location']['country']['code'] == 'us': continue\n",
    "        \n",
    "    transformed_location = c['location']['name']\n",
    "    for transform in transforms:\n",
    "        transformed_location = transformed_location.replace(*transform)\n",
    "    \n",
    "    geo = g.geocode(transformed_location, exactly_one=False)\n",
    "    if geo == []: continue\n",
    "    parsed_state = parseStateFromBingResult(geo)\n",
    "    if parsed_state != \"???\":\n",
    "        results.update({c['location']['name'] : parsed_state})\n",
    "    \n",
    "print json.dumps(results, indent=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's how to power a Cartogram visualization with the data from the \"results\" variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display\n",
    "\n",
    "# Load in a data structure mapping state names to codes.\n",
    "# e.g. West Virginia is WV\n",
    "codes = json.loads(open('resources/ch03-linkedin/viz/states-codes.json').read())\n",
    "\n",
    "from collections import Counter\n",
    "c = Counter([r[1] for r in results.items()])\n",
    "states_freqs = { codes[k] : v for (k,v) in c.items() }\n",
    "\n",
    "# Lace in all of the other states and provide a minimum value for each of them\n",
    "states_freqs.update({v : 0.5 for v in codes.values() if v not in states_freqs.keys() })\n",
    "\n",
    "# Write output to file\n",
    "f = open('resources/ch03-linkedin/viz/states-freqs.json', 'w')\n",
    "f.write(json.dumps(states_freqs, indent=1))\n",
    "f.close()\n",
    "\n",
    "# IPython Notebook can serve files and display them into\n",
    "# inline frames. Prepend the path with the 'files' prefix\n",
    "\n",
    "display(IFrame('files/resources/ch03-linkedin/viz/cartogram.html', '100%', '600px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 11. Using NLTK to compute bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "ceo_bigrams = nltk.bigrams(\"Chief Executive Officer\".split(), pad_right=True, \n",
    "                                                              pad_left=True)\n",
    "cto_bigrams = nltk.bigrams(\"Chief Technology Officer\".split(), pad_right=True, \n",
    "                                                               pad_left=True)\n",
    "\n",
    "print ceo_bigrams\n",
    "print cto_bigrams\n",
    "print len(set(ceo_bigrams).intersection(set(cto_bigrams)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 12. Clustering job titles using a greedy heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
    "# http://www.linkedin.com/people/export-settings at the following\n",
    "# location: resources/ch03-linkedin/my_connections.csv\n",
    "\n",
    "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
    "\n",
    "# Tweak this distance threshold and try different distance calculations \n",
    "# during experimentation\n",
    "DISTANCE_THRESHOLD = 0.5\n",
    "DISTANCE = jaccard_distance\n",
    "\n",
    "def cluster_contacts_by_title(csv_file):\n",
    "\n",
    "    transforms = [\n",
    "        ('Sr.', 'Senior'),\n",
    "        ('Sr', 'Senior'),\n",
    "        ('Jr.', 'Junior'),\n",
    "        ('Jr', 'Junior'),\n",
    "        ('CEO', 'Chief Executive Officer'),\n",
    "        ('COO', 'Chief Operating Officer'),\n",
    "        ('CTO', 'Chief Technology Officer'),\n",
    "        ('CFO', 'Chief Finance Officer'),\n",
    "        ('VP', 'Vice President'),\n",
    "        ]\n",
    "\n",
    "    separators = ['/', ' and ', '&']\n",
    "\n",
    "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
    "    contacts = [row for row in csvReader]\n",
    "\n",
    "    # Normalize and/or replace known abbreviations\n",
    "    # and build up a list of common titles.\n",
    "\n",
    "    all_titles = []\n",
    "    for i, _ in enumerate(contacts):\n",
    "        if contacts[i]['Job Title'] == '':\n",
    "            contacts[i]['Job Titles'] = ['']\n",
    "            continue\n",
    "        titles = [contacts[i]['Job Title'].strip()]\n",
    "        for title in titles:\n",
    "            for separator in separators:\n",
    "                if title.find(separator) >= 0:\n",
    "                    titles.remove(title.strip())\n",
    "                    titles.extend([title.strip() for title in title.split(separator)\n",
    "                                  if title.strip() != ''])\n",
    "\n",
    "        for transform in transforms:\n",
    "            titles = [title.replace(*transform) for title in titles]\n",
    "        contacts[i]['Job Titles'] = titles\n",
    "        all_titles.extend(titles)\n",
    "\n",
    "    all_titles = list(set(all_titles))\n",
    "\n",
    "    clusters = {}\n",
    "    for title1 in all_titles:\n",
    "        clusters[title1] = []\n",
    "        for title2 in all_titles:\n",
    "            if title2 in clusters[title1] or clusters.has_key(title2) and title1 \\\n",
    "                in clusters[title2]:\n",
    "                continue\n",
    "            distance = DISTANCE(set(title1.split()), set(title2.split()))\n",
    "\n",
    "            if distance < DISTANCE_THRESHOLD:\n",
    "                clusters[title1].append(title2)\n",
    "\n",
    "    # Flatten out clusters\n",
    "\n",
    "    clusters = [clusters[title] for title in clusters if len(clusters[title]) > 1]\n",
    "\n",
    "    # Round up contacts who are in these clusters and group them together\n",
    "\n",
    "    clustered_contacts = {}\n",
    "    for cluster in clusters:\n",
    "        clustered_contacts[tuple(cluster)] = []\n",
    "        for contact in contacts:\n",
    "            for title in contact['Job Titles']:\n",
    "                if title in cluster:\n",
    "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
    "                            % (contact['First Name'], contact['Last Name']))\n",
    "\n",
    "    return clustered_contacts\n",
    "\n",
    "\n",
    "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
    "print clustered_contacts\n",
    "for titles in clustered_contacts:\n",
    "    common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
    "\n",
    "    descriptive_terms = set(titles[0].split())\n",
    "    for title in titles:\n",
    "        descriptive_terms.intersection_update(set(title.split()))\n",
    "    descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
    "        + ', '.join(descriptive_terms)\n",
    "    print descriptive_terms_heading\n",
    "    print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
    "    print '\\n'.join(clustered_contacts[titles])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Incorporating random sampling can improve performance of the nested loops in Example 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
    "# http://www.linkedin.com/people/export-settings at the following\n",
    "# location: resources/ch03-linkedin/my_connections.csv\n",
    "\n",
    "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
    "\n",
    "# Tweak this distance threshold and try different distance calculations \n",
    "# during experimentation\n",
    "DISTANCE_THRESHOLD = 0.5\n",
    "DISTANCE = jaccard_distance\n",
    "\n",
    "# Adjust sample size as needed to reduce the runtime of the\n",
    "# nested loop that invokes the DISTANCE function\n",
    "SAMPLE_SIZE = 500\n",
    "\n",
    "def cluster_contacts_by_title(csv_file):\n",
    "\n",
    "    transforms = [\n",
    "        ('Sr.', 'Senior'),\n",
    "        ('Sr', 'Senior'),\n",
    "        ('Jr.', 'Junior'),\n",
    "        ('Jr', 'Junior'),\n",
    "        ('CEO', 'Chief Executive Officer'),\n",
    "        ('COO', 'Chief Operating Officer'),\n",
    "        ('CTO', 'Chief Technology Officer'),\n",
    "        ('CFO', 'Chief Finance Officer'),\n",
    "        ('VP', 'Vice President'),\n",
    "        ]\n",
    "\n",
    "    separators = ['/', ' and ', '&']\n",
    "\n",
    "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
    "    contacts = [row for row in csvReader]\n",
    "\n",
    "    # Normalize and/or replace known abbreviations\n",
    "    # and build up list of common titles\n",
    "\n",
    "    all_titles = []\n",
    "    for i, _ in enumerate(contacts):\n",
    "        if contacts[i]['Job Title'] == '':\n",
    "            contacts[i]['Job Titles'] = ['']\n",
    "            continue\n",
    "        titles = [contacts[i]['Job Title'].strip()]\n",
    "        for title in titles:\n",
    "            for separator in separators:\n",
    "                if title.find(separator) >= 0:\n",
    "                    titles.remove(title.strip())\n",
    "                    titles.extend([title.strip() for title in title.split(separator)\n",
    "                                  if title.strip() != ''])\n",
    "\n",
    "        for transform in transforms:\n",
    "            titles = [title.replace(*transform) for title in titles]\n",
    "        contacts[i]['Job Titles'] = titles\n",
    "        all_titles.extend(titles)\n",
    "\n",
    "    all_titles = list(set(all_titles))\n",
    "    clusters = {}\n",
    "    for title1 in all_titles:\n",
    "        clusters[title1] = []\n",
    "        for sample in xrange(SAMPLE_SIZE):\n",
    "            title2 = all_titles[random.randint(0, len(all_titles)-1)]\n",
    "            if title2 in clusters[title1] or clusters.has_key(title2) and title1 \\\n",
    "                in clusters[title2]:\n",
    "                continue\n",
    "            distance = DISTANCE(set(title1.split()), set(title2.split()))\n",
    "            if distance < DISTANCE_THRESHOLD:\n",
    "                clusters[title1].append(title2)\n",
    "\n",
    "    # Flatten out clusters\n",
    "\n",
    "    clusters = [clusters[title] for title in clusters if len(clusters[title]) > 1]\n",
    "\n",
    "    # Round up contacts who are in these clusters and group them together\n",
    "\n",
    "    clustered_contacts = {}\n",
    "    for cluster in clusters:\n",
    "        clustered_contacts[tuple(cluster)] = []\n",
    "        for contact in contacts:\n",
    "            for title in contact['Job Titles']:\n",
    "                if title in cluster:\n",
    "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
    "                            % (contact['First Name'], contact['Last Name']))\n",
    "\n",
    "    return clustered_contacts\n",
    "\n",
    "\n",
    "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
    "print clustered_contacts\n",
    "for titles in clustered_contacts:\n",
    "    common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
    "\n",
    "    descriptive_terms = set(titles[0].split())\n",
    "    for title in titles:\n",
    "        descriptive_terms.intersection_update(set(title.split()))\n",
    "    descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
    "        + ', '.join(descriptive_terms)\n",
    "    print descriptive_terms_heading\n",
    "    print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
    "    print '\\n'.join(clustered_contacts[titles])\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to export data (contained in the \"clustered contacts\" variable) to power faceted display as outlined in Figure 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display\n",
    "\n",
    "data = {\"label\" : \"name\", \"temp_items\" : {}, \"items\" : []} \n",
    "for titles in clustered_contacts:\n",
    "    descriptive_terms = set(titles[0].split())\n",
    "    for title in titles:\n",
    "        descriptive_terms.intersection_update(set(title.split()))\n",
    "    descriptive_terms = ', '.join(descriptive_terms)\n",
    "\n",
    "    if data['temp_items'].has_key(descriptive_terms):\n",
    "        data['temp_items'][descriptive_terms].extend([{'name' : cc } for cc \n",
    "            in clustered_contacts[titles]])\n",
    "    else:\n",
    "        data['temp_items'][descriptive_terms] = [{'name' : cc } for cc \n",
    "            in clustered_contacts[titles]]\n",
    "\n",
    "for descriptive_terms in data['temp_items']:\n",
    "    data['items'].append({\"name\" : \"%s (%s)\" % (descriptive_terms, \n",
    "        len(data['temp_items'][descriptive_terms]),),\n",
    "                              \"children\" : [i for i in \n",
    "                              data['temp_items'][descriptive_terms]]})\n",
    "\n",
    "del data['temp_items']\n",
    "\n",
    "# Open the template and substitute the data\n",
    "\n",
    "TEMPLATE = 'resources/ch03-linkedin/viz/dojo_tree.html.template'                                                \n",
    "OUT = 'resources/ch03-linkedin/viz/dojo_tree.html'\n",
    "\n",
    "viz_file = 'files/resources/ch03-linkedin/viz/dojo_tree.html'\n",
    "\n",
    "t = open(TEMPLATE).read()\n",
    "f = open(OUT, 'w')\n",
    "f.write(t % json.dumps(data, indent=4))\n",
    "f.close()\n",
    "\n",
    "# IPython Notebook can serve files and display them into\n",
    "# inline frames. Prepend the path with the 'files' prefix\n",
    "\n",
    "display(IFrame(viz_file, '400px', '600px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to export data to power a dendogram and node-link tree visualization as outlined in Figure 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from cluster import HierarchicalClustering\n",
    "\n",
    "# XXX: Place your \"Outlook CSV\" formatted file of connections from \n",
    "# http://www.linkedin.com/people/export-settings at the following\n",
    "# location: resources/ch03-linkedin/my_connections.csv\n",
    "\n",
    "CSV_FILE = os.path.join(\"resources\", \"ch03-linkedin\", 'my_connections.csv')\n",
    "\n",
    "OUT_FILE = 'resources/ch03-linkedin/viz/d3-data.json'\n",
    "\n",
    "# Tweak this distance threshold and try different distance calculations \n",
    "# during experimentation\n",
    "DISTANCE_THRESHOLD = 0.5\n",
    "DISTANCE = jaccard_distance\n",
    "\n",
    "# Adjust sample size as needed to reduce the runtime of the\n",
    "# nested loop that invokes the DISTANCE function\n",
    "SAMPLE_SIZE = 500\n",
    "\n",
    "def cluster_contacts_by_title(csv_file):\n",
    "\n",
    "    transforms = [\n",
    "        ('Sr.', 'Senior'),\n",
    "        ('Sr', 'Senior'),\n",
    "        ('Jr.', 'Junior'),\n",
    "        ('Jr', 'Junior'),\n",
    "        ('CEO', 'Chief Executive Officer'),\n",
    "        ('COO', 'Chief Operating Officer'),\n",
    "        ('CTO', 'Chief Technology Officer'),\n",
    "        ('CFO', 'Chief Finance Officer'),\n",
    "        ('VP', 'Vice President'),\n",
    "        ]\n",
    "\n",
    "    separators = ['/', 'and', '&']\n",
    "\n",
    "    csvReader = csv.DictReader(open(csv_file), delimiter=',', quotechar='\"')\n",
    "    contacts = [row for row in csvReader]\n",
    "\n",
    "    # Normalize and/or replace known abbreviations\n",
    "    # and build up list of common titles\n",
    "\n",
    "    all_titles = []\n",
    "    for i, _ in enumerate(contacts):\n",
    "        if contacts[i]['Job Title'] == '':\n",
    "            contacts[i]['Job Titles'] = ['']\n",
    "            continue\n",
    "        titles = [contacts[i]['Job Title']]\n",
    "        for title in titles:\n",
    "            for separator in separators:\n",
    "                if title.find(separator) >= 0:\n",
    "                    titles.remove(title)\n",
    "                    titles.extend([title.strip() for title in title.split(separator)\n",
    "                                  if title.strip() != ''])\n",
    "\n",
    "        for transform in transforms:\n",
    "            titles = [title.replace(*transform) for title in titles]\n",
    "        contacts[i]['Job Titles'] = titles\n",
    "        all_titles.extend(titles)\n",
    "\n",
    "    all_titles = list(set(all_titles))\n",
    "    \n",
    "    # Define a scoring function\n",
    "    def score(title1, title2): \n",
    "        return DISTANCE(set(title1.split()), set(title2.split()))\n",
    "\n",
    "    # Feed the class your data and the scoring function\n",
    "    hc = HierarchicalClustering(all_titles, score)\n",
    "\n",
    "    # Cluster the data according to a distance threshold\n",
    "    clusters = hc.getlevel(DISTANCE_THRESHOLD)\n",
    "\n",
    "    # Remove singleton clusters\n",
    "    clusters = [c for c in clusters if len(c) > 1]\n",
    "\n",
    "    # Round up contacts who are in these clusters and group them together\n",
    "\n",
    "    clustered_contacts = {}\n",
    "    for cluster in clusters:\n",
    "        clustered_contacts[tuple(cluster)] = []\n",
    "        for contact in contacts:\n",
    "            for title in contact['Job Titles']:\n",
    "                if title in cluster:\n",
    "                    clustered_contacts[tuple(cluster)].append('%s %s'\n",
    "                            % (contact['First Name'], contact['Last Name']))\n",
    "\n",
    "    return clustered_contacts\n",
    "\n",
    "def display_output(clustered_contacts):\n",
    "    \n",
    "    for titles in clustered_contacts:\n",
    "        common_titles_heading = 'Common Titles: ' + ', '.join(titles)\n",
    "\n",
    "        descriptive_terms = set(titles[0].split())\n",
    "        for title in titles:\n",
    "            descriptive_terms.intersection_update(set(title.split()))\n",
    "        descriptive_terms_heading = 'Descriptive Terms: ' \\\n",
    "            + ', '.join(descriptive_terms)\n",
    "        print descriptive_terms_heading\n",
    "        print '-' * max(len(descriptive_terms_heading), len(common_titles_heading))\n",
    "        print '\\n'.join(clustered_contacts[titles])\n",
    "        print\n",
    "\n",
    "def write_d3_json_output(clustered_contacts):\n",
    "    \n",
    "    json_output = {'name' : 'My LinkedIn', 'children' : []}\n",
    "\n",
    "    for titles in clustered_contacts:\n",
    "\n",
    "        descriptive_terms = set(titles[0].split())\n",
    "        for title in titles:\n",
    "            descriptive_terms.intersection_update(set(title.split()))\n",
    "\n",
    "        json_output['children'].append({'name' : ', '.join(descriptive_terms)[:30], \n",
    "                                    'children' : [ {'name' : c.decode('utf-8', 'replace')} for c in clustered_contacts[titles] ] } )\n",
    "    \n",
    "        f = open(OUT_FILE, 'w')\n",
    "        f.write(json.dumps(json_output, indent=1))\n",
    "        f.close()\n",
    "    \n",
    "clustered_contacts = cluster_contacts_by_title(CSV_FILE)\n",
    "display_output(clustered_contacts)\n",
    "write_d3_json_output(clustered_contacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once you've run the code and produced the output for the dendogram and node-link tree visualizations, here's one way to serve it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import IFrame\n",
    "from IPython.core.display import display\n",
    "\n",
    "# IPython Notebook can serve files and display them into\n",
    "# inline frames. Prepend the path with the 'files' prefix\n",
    "\n",
    "viz_file = 'files/resources/ch03-linkedin/viz/node_link_tree.html'\n",
    "\n",
    "# XXX: Another visualization you could try:\n",
    "#viz_file = 'files/resources/ch03-linkedin/viz/dendogram.html'\n",
    "\n",
    "display(IFrame(viz_file, '100%', '600px'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 13. Clustering your LinkedIn professional network based upon the locations of your connections and emitting KML output for visualization with Google Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from urllib2 import HTTPError\n",
    "from geopy import geocoders\n",
    "from cluster import KMeansClustering, centroid\n",
    "\n",
    "# A helper function to munge data and build up an XML tree.\n",
    "# It references some code tucked away in another directory, so we have to\n",
    "# add that directory to the PYTHONPATH for it to be picked up.\n",
    "sys.path.append(os.path.join(os.getcwd(), \"resources\", \"ch03-linkedin\"))\n",
    "from linkedin__kml_utility import createKML\n",
    "\n",
    "# XXX: Try different values for K to see the difference in clusters that emerge\n",
    "\n",
    "K = 3\n",
    "\n",
    "# XXX: Get an API key and pass it in here. See https://www.bingmapsportal.com.\n",
    "GEO_API_KEY = ''\n",
    "g = geocoders.Bing(GEO_API_KEY)\n",
    "\n",
    "# Load this data from where you've previously stored it\n",
    "\n",
    "CONNECTIONS_DATA = 'resources/ch03-linkedin/linkedin_connections.json'\n",
    "\n",
    "OUT_FILE = \"resources/ch03-linkedin/viz/linkedin_clusters_kmeans.kml\"\n",
    "\n",
    "# Open up your saved connections with extended profile information\n",
    "# or fetch them again from LinkedIn if you prefer\n",
    "\n",
    "connections = json.loads(open(CONNECTIONS_DATA).read())['values']\n",
    "\n",
    "locations = [c['location']['name'] for c in connections if c.has_key('location')]\n",
    "\n",
    "# Some basic transforms may be necessary for geocoding services to function properly\n",
    "# Here are a couple that seem to help.\n",
    "\n",
    "transforms = [('Greater ', ''), (' Area', '')]\n",
    "\n",
    "# Step 1 - Tally the frequency of each location\n",
    "\n",
    "coords_freqs = {}\n",
    "for location in locations:\n",
    "\n",
    "    if not c.has_key('location'): continue\n",
    "    \n",
    "    # Avoid unnecessary I/O and geo requests by building up a cache\n",
    "\n",
    "    if coords_freqs.has_key(location):\n",
    "        coords_freqs[location][1] += 1\n",
    "        continue\n",
    "    transformed_location = location\n",
    "\n",
    "    for transform in transforms:\n",
    "        transformed_location = transformed_location.replace(*transform)\n",
    "        \n",
    "        # Handle potential I/O errors with a retry pattern...\n",
    "        \n",
    "        while True:\n",
    "            num_errors = 0\n",
    "            try:\n",
    "                results = g.geocode(transformed_location, exactly_one=False)\n",
    "                break\n",
    "            except HTTPError, e:\n",
    "                num_errors += 1\n",
    "                if num_errors >= 3:\n",
    "                    sys.exit()\n",
    "                print >> sys.stderr, e\n",
    "                print >> sys.stderr, 'Encountered an urllib2 error. Trying again...'\n",
    "                \n",
    "        for result in results:\n",
    "            # Each result is of the form (\"Description\", (X,Y))\n",
    "            coords_freqs[location] = [result[1], 1]\n",
    "            break # Disambiguation strategy is \"pick first\"\n",
    "\n",
    "# Step 2 - Build up data structure for converting locations to KML            \n",
    "            \n",
    "# Here, you could optionally segment locations by continent or country\n",
    "# so as to avoid potentially finding a mean in the middle of the ocean.\n",
    "# The k-means algorithm will expect distinct points for each contact, so\n",
    "# build out an expanded list to pass it.\n",
    "\n",
    "expanded_coords = []\n",
    "for label in coords_freqs:\n",
    "    # Flip lat/lon for Google Earth\n",
    "    ((lat, lon), f) = coords_freqs[label]\n",
    "    expanded_coords.append((label, [(lon, lat)] * f))\n",
    "\n",
    "# No need to clutter the map with unnecessary placemarks...\n",
    "\n",
    "kml_items = [{'label': label, 'coords': '%s,%s' % coords[0]} for (label,\n",
    "             coords) in expanded_coords]\n",
    "\n",
    "# It would also be helpful to include names of your contacts on the map\n",
    "\n",
    "for item in kml_items:\n",
    "    item['contacts'] = '\\n'.join(['%s %s.' % (c['firstName'], c['lastName'])\n",
    "        for c in connections if c.has_key('location') and \n",
    "                                c['location']['name'] == item['label']])\n",
    "\n",
    "# Step 3 - Cluster locations and extend the KML data structure with centroids\n",
    "    \n",
    "cl = KMeansClustering([coords for (label, coords_list) in expanded_coords\n",
    "                      for coords in coords_list])\n",
    "\n",
    "centroids = [{'label': 'CENTROID', 'coords': '%s,%s' % centroid(c)} for c in\n",
    "             cl.getclusters(K)]\n",
    "\n",
    "kml_items.extend(centroids)\n",
    "\n",
    "# Step 4 - Create the final KML output and write it to a file\n",
    "\n",
    "kml = createKML(kml_items)\n",
    "\n",
    "f = open(OUT_FILE, 'w')\n",
    "f.write(kml)\n",
    "f.close()\n",
    "\n",
    "print 'Data written to ' + OUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] 소셜 웹 마이닝 소셜미디어 데이터 마이닝 및 분석 2판 - http://www.kyobobook.co.kr/product/detailViewKor.laf?ejkGb=KOR&mallGb=KOR&barcode=9788994774893\n",
    "* [2] 저자 소스코드 - http://bit.ly/16kGNyb\n",
    "* [3] 링크드인 개발자 플랫폼 - https://www.linkedin.com/secure/developer\n",
    "* [4] 링크드인 auth2 관련 공식 문서 - https://developer.linkedin.com/docs/oauth2\n",
    "* [5] 링크드인 api + auth2  슬라이드 - http://www.slideshare.net/KamyarMohager/o-auth-2-and-linked-inpdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
